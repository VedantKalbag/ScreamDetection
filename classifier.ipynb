{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.io.wavfile, scipy.signal\n",
    "from scipy.spatial import distance\n",
    "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre-Processing Data\n",
    "- Load Ground Truth from annotation.csv at 44.1kHz\n",
    "- Load audio files for each song\n",
    "    1. Average L+R to convert to mono audio\n",
    "    2. Divide into 5 second windows with 1 second hop\\\n",
    "    3. Label each hop based on whether its midpoint is within the start and end times annotated "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# BLOCK AUDIO\n",
    "def block_audio(x,blockSize,hopSize,fs):    \n",
    "    # allocate memory    \n",
    "    numBlocks = math.ceil(x.size / hopSize)    \n",
    "    xb = np.zeros([numBlocks, blockSize])    \n",
    "    # compute time stamps    \n",
    "    t = (np.arange(0, numBlocks) * hopSize) / fs   \n",
    "    t_mid = t + (0.5*blockSize/fs)\n",
    "    x = np.concatenate((x, np.zeros(blockSize)),axis=0)    \n",
    "    for n in range(0, numBlocks):        \n",
    "        i_start = n * hopSize        \n",
    "        i_stop = np.min([x.size - 1, i_start + blockSize - 1])        \n",
    "        xb[n][np.arange(0,blockSize)] = x[np.arange(i_start, i_stop + 1)]    \n",
    "    return (xb,t,t_mid)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "video_id = '_duhhVa-dk8'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "x,sr = librosa.load('./resources/dataset/Audio/processed/'+video_id+'.wav',sr=44100,mono=True)#scipy.io.wavfile.read('./resources/dataset/Audio/processed/'+file_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "blockSize = int(sr * 1)\n",
    "hopSize = int(sr * 0.5)\n",
    "\n",
    "xb,t,t_mid = block_audio(x,blockSize,hopSize,sr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "lut=pd.read_csv('./resources/dataset/Annotations/final/annotation.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Testing logic for labelling data based on ground truth\n",
    "\n",
    "blocks = t_mid.size\n",
    "i=0\n",
    "\n",
    "for ts in t_mid:\n",
    "    for idx,row in lut[lut['video_id'] == video_id].reset_index().iterrows():\n",
    "        annotated_start = row['timestamp_start']\n",
    "        annotated_end = row['timestamp_end']\n",
    "        if annotated_start <= ts <= annotated_end:\n",
    "            #print(f\"ts - {ts}, start - {annotated_start} and end - {annotated_end}\")\n",
    "            i+=1\n",
    "            break\n",
    "    if ~(annotated_start <= ts <= annotated_end):\n",
    "        i+=1         \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below paragraph takes about 282 s"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "lut=pd.read_csv('./resources/dataset/Annotations/final/annotation.csv')\n",
    "i=0\n",
    "for video_id in lut['video_id'].unique():\n",
    "    x,sr = librosa.load('./resources/dataset/Audio/processed/'+video_id+'.wav',sr=44100,mono=True)\n",
    "    blockSize = int(sr * 1)\n",
    "    hopSize = int(sr * 0.5)\n",
    "\n",
    "    xb,t,t_mid = block_audio(x,blockSize,hopSize,sr)\n",
    "    labels=[]\n",
    "    for ts in t_mid:\n",
    "        for idx,row in lut[lut['video_id'] == video_id].reset_index().iterrows():\n",
    "            annotated_start = row['timestamp_start']\n",
    "            annotated_end = row['timestamp_end']\n",
    "            if annotated_start <= ts <= annotated_end:\n",
    "                labels.append(row['scream_type'])\n",
    "                break\n",
    "        if ~(annotated_start <= ts <= annotated_end):\n",
    "            labels.append('no_vocals')\n",
    "    # Create new dataframs\n",
    "    if i == 0:\n",
    "        df=pd.DataFrame()\n",
    "\n",
    "        df['t'] = t\n",
    "        df['t_mid'] = t_mid\n",
    "        blocks=[]\n",
    "        for blk in xb:\n",
    "            blocks.append(blk)\n",
    "        df.insert(0,'video_id',video_id)\n",
    "        df.insert(3,'label',labels)\n",
    "        df['xb'] = blocks\n",
    "        i+=1\n",
    "    else:\n",
    "        tmp=pd.DataFrame()\n",
    "        tmp['t'] = t\n",
    "        tmp['t_mid'] = t_mid\n",
    "        blocks=[]\n",
    "        for blk in xb:\n",
    "            blocks.append(blk)\n",
    "        tmp['video_id'] = video_id\n",
    "        tmp['label'] = labels\n",
    "        tmp['xb'] = blocks\n",
    "        df=df.append(tmp)\n",
    "out = df.to_numpy()\n",
    "np.save('./resources/working_data/data.npy', out)\n",
    "    #df.to_csv('./resources/working_data/'+video_id+'.csv',header=True, index=False,encoding='utf-8-sig',sep='\\t')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extract Features\n",
    "## 13 delta_mfccs, ZCR, Spectral Crest, Spectral Centroid\n",
    "- Normalize the features across the entire dataset\n",
    "- Extract mean, std dev of the feature value per block \n",
    "- Calculate change in feature from one block to another\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below paragraph takes about 16 s"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "d=np.load('./resources/working_data/data.npy',allow_pickle=True)\n",
    "df = pd.DataFrame(d,columns=['video_id','ts','mid_ts','label','audio'])\n",
    "\n",
    "lut = pd.read_csv('./resources/dataset/lookup_new.csv')\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "train_inds, test_inds = next(GroupShuffleSplit(test_size=.33, n_splits=2, random_state = 0).split(lut, groups=lut['band_name']))\n",
    "\n",
    "train = lut.iloc[train_inds]\n",
    "test = lut.iloc[test_inds]\n",
    "\n",
    "train_ids = train['video_id'].to_numpy()\n",
    "test_ids = test['video_id'].to_numpy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "def agg_mfccs(x):\n",
    "    mfccs = librosa.feature.mfcc(x,n_mfcc = 13)\n",
    "    mean = [np.mean(feature) for feature in mfccs]\n",
    "    std = [np.std(feature) for feature in mfccs]\n",
    "    mfcc_delta = librosa.feature.delta(mfccs)\n",
    "    delta_mean=[np.mean(feature) for feature in mfcc_delta]\n",
    "    delta_std=[np.std(feature) for feature in mfcc_delta]\n",
    "    return mean,std,delta_mean,delta_std"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "def extract_features(x):\n",
    "    #MFCCs\n",
    "    mfcc_mean,mfcc_std,delta_mfcc_mean,delta_mfcc_std = agg_mfccs(x)\n",
    "    #ZCR\n",
    "    zcr=librosa.feature.zero_crossing_rate(x)\n",
    "\n",
    "\n",
    "    \n",
    "    return mfcc_mean,mfcc_std,delta_mfcc_mean,delta_mfcc_std,zcr"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below paragraph takes about 420 s"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "df['zcr'] = ''\n",
    "df['average_zcr'] = ''\n",
    "df['zcr_stddev'] = ''\n",
    "\n",
    "#df['mfccs'] = ''\n",
    "df['mfcc_mean'] = ''\n",
    "df['mfcc_std'] = ''\n",
    "\n",
    "df['delta_mfcc_mean'] = ''\n",
    "df['delta_mfcc_std'] = ''\n",
    "\n",
    "for i in range(len(df)):\n",
    "    # Calculate ZCR (3 features)\n",
    "    zcr=librosa.feature.zero_crossing_rate(df['audio'][i])\n",
    "    df['zcr'][i] = zcr\n",
    "    df['average_zcr'][i] = np.mean(zcr)\n",
    "    df['zcr_stddev'][i] = np.std(zcr)\n",
    "\n",
    "    # Extract 13 MFCCs - get mean and std deviation for each (26 features) + Delta MFCCs (26 features) = total 52 Features\n",
    "    mean,std,delta_mean,delta_std = agg_mfccs(df['audio'][i])\n",
    "    #df['mfccs'][i] = mfccs[0]\n",
    "    df['mfcc_mean'][i] = mean\n",
    "    df['mfcc_std'][i] = std\n",
    "\n",
    "    df['delta_mfcc_mean'][i] = delta_mean\n",
    "    df['delta_mfcc_std'][i] = delta_std\n",
    "\n",
    "# Find change in MFCC from one block to another (group by video_id)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "df[['mfcc1_mean','mfcc2_mean','mfcc3_mean','mfcc4_mean','mfcc5_mean','mfcc6_mean','mfcc7_mean','mfcc8_mean','mfcc9_mean','mfcc10_mean','mfcc11_mean','mfcc12_mean','mfcc13_mean']]=pd.DataFrame(df.mfcc_mean.tolist(), index= df.index)\n",
    "df[['mfcc1_std','mfcc2_std','mfcc3_std','mfcc4_std','mfcc5_std','mfcc6_std','mfcc7_std','mfcc8_std','mfcc9_std','mfcc10_std','mfcc11_std','mfcc12_std','mfcc13_std']]=pd.DataFrame(df.mfcc_std.tolist(), index= df.index)\n",
    "\n",
    "df[['delta_mfcc1_mean','delta_mfcc2_mean','delta_mfcc3_mean','delta_mfcc4_mean','delta_mfcc5_mean','delta_mfcc6_mean','delta_mfcc7_mean','delta_mfcc8_mean','delta_mfcc9_mean','delta_mfcc10_mean','delta_mfcc11_mean','delta_mfcc12_mean','delta_mfcc13_mean']]=pd.DataFrame(df.delta_mfcc_mean.tolist(), index= df.index)\n",
    "df[['delta_mfcc1_std','delta_mfcc2_std','delta_mfcc3_std','delta_mfcc4_std','delta_mfcc5_std','delta_mfcc6_std','delta_mfcc7_std','delta_mfcc8_std','delta_mfcc9_std','delta_mfcc10_std','delta_mfcc11_std','delta_mfcc12_std','delta_mfcc13_std']]=pd.DataFrame(df.delta_mfcc_std.tolist(), index= df.index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "df.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['video_id', 'ts', 'mid_ts', 'label', 'audio', 'zcr', 'average_zcr',\n",
       "       'zcr_stddev', 'mfcc_mean', 'mfcc_std', 'delta_mfcc_mean',\n",
       "       'delta_mfcc_std', 'mfcc1_mean', 'mfcc2_mean', 'mfcc3_mean',\n",
       "       'mfcc4_mean', 'mfcc5_mean', 'mfcc6_mean', 'mfcc7_mean', 'mfcc8_mean',\n",
       "       'mfcc9_mean', 'mfcc10_mean', 'mfcc11_mean', 'mfcc12_mean',\n",
       "       'mfcc13_mean', 'mfcc1_std', 'mfcc2_std', 'mfcc3_std', 'mfcc4_std',\n",
       "       'mfcc5_std', 'mfcc6_std', 'mfcc7_std', 'mfcc8_std', 'mfcc9_std',\n",
       "       'mfcc10_std', 'mfcc11_std', 'mfcc12_std', 'mfcc13_std',\n",
       "       'delta_mfcc1_mean', 'delta_mfcc2_mean', 'delta_mfcc3_mean',\n",
       "       'delta_mfcc4_mean', 'delta_mfcc5_mean', 'delta_mfcc6_mean',\n",
       "       'delta_mfcc7_mean', 'delta_mfcc8_mean', 'delta_mfcc9_mean',\n",
       "       'delta_mfcc10_mean', 'delta_mfcc11_mean', 'delta_mfcc12_mean',\n",
       "       'delta_mfcc13_mean', 'delta_mfcc1_std', 'delta_mfcc2_std',\n",
       "       'delta_mfcc3_std', 'delta_mfcc4_std', 'delta_mfcc5_std',\n",
       "       'delta_mfcc6_std', 'delta_mfcc7_std', 'delta_mfcc8_std',\n",
       "       'delta_mfcc9_std', 'delta_mfcc10_std', 'delta_mfcc11_std',\n",
       "       'delta_mfcc12_std', 'delta_mfcc13_std'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "np.save('./resources/working_data/data_with_features.npy', df.to_numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "df.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(33820, 64)"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "train = df[df.video_id.isin(train_ids)]\n",
    "test = df[df.video_id.isin(test_ids)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "train.groupby('label')['audio'].count()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "label\n",
       "clean         1988\n",
       "highfry        659\n",
       "layered        392\n",
       "lowfry         161\n",
       "midfry        5602\n",
       "no_vocals    10836\n",
       "Name: audio, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "test.groupby('label')['audio'].count()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "label\n",
       "clean         474\n",
       "highfry       664\n",
       "layered       485\n",
       "lowfry        394\n",
       "midfry       3932\n",
       "no_vocals    8233\n",
       "Name: audio, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "X_train = train[['average_zcr','zcr_stddev','mfcc1_mean', 'mfcc2_mean', 'mfcc3_mean','mfcc4_mean', 'mfcc5_mean', 'mfcc6_mean', 'mfcc7_mean', 'mfcc8_mean','mfcc9_mean', 'mfcc10_mean', 'mfcc11_mean', 'mfcc12_mean','mfcc13_mean', 'mfcc1_std', 'mfcc2_std', 'mfcc3_std', 'mfcc4_std','mfcc5_std', 'mfcc6_std', 'mfcc7_std', 'mfcc8_std', 'mfcc9_std','mfcc10_std', 'mfcc11_std', 'mfcc12_std', 'mfcc13_std','delta_mfcc1_mean', 'delta_mfcc2_mean', 'delta_mfcc3_mean','delta_mfcc4_mean', 'delta_mfcc5_mean', 'delta_mfcc6_mean','delta_mfcc7_mean', 'delta_mfcc8_mean', 'delta_mfcc9_mean','delta_mfcc10_mean', 'delta_mfcc11_mean', 'delta_mfcc12_mean','delta_mfcc13_mean', 'delta_mfcc1_std', 'delta_mfcc2_std','delta_mfcc3_std', 'delta_mfcc4_std', 'delta_mfcc5_std','delta_mfcc6_std', 'delta_mfcc7_std', 'delta_mfcc8_std','delta_mfcc9_std', 'delta_mfcc10_std', 'delta_mfcc11_std','delta_mfcc12_std', 'delta_mfcc13_std']].to_numpy()\n",
    "y_train=train[['label']].to_numpy()\n",
    "\n",
    "X_test = test[['average_zcr','zcr_stddev', 'mfcc1_mean', 'mfcc2_mean', 'mfcc3_mean','mfcc4_mean', 'mfcc5_mean', 'mfcc6_mean', 'mfcc7_mean', 'mfcc8_mean','mfcc9_mean', 'mfcc10_mean', 'mfcc11_mean', 'mfcc12_mean','mfcc13_mean', 'mfcc1_std', 'mfcc2_std', 'mfcc3_std', 'mfcc4_std','mfcc5_std', 'mfcc6_std', 'mfcc7_std', 'mfcc8_std', 'mfcc9_std','mfcc10_std', 'mfcc11_std', 'mfcc12_std', 'mfcc13_std','delta_mfcc1_mean', 'delta_mfcc2_mean', 'delta_mfcc3_mean','delta_mfcc4_mean', 'delta_mfcc5_mean', 'delta_mfcc6_mean','delta_mfcc7_mean', 'delta_mfcc8_mean', 'delta_mfcc9_mean','delta_mfcc10_mean', 'delta_mfcc11_mean', 'delta_mfcc12_mean','delta_mfcc13_mean', 'delta_mfcc1_std', 'delta_mfcc2_std','delta_mfcc3_std', 'delta_mfcc4_std', 'delta_mfcc5_std','delta_mfcc6_std', 'delta_mfcc7_std', 'delta_mfcc8_std','delta_mfcc9_std', 'delta_mfcc10_std', 'delta_mfcc11_std','delta_mfcc12_std', 'delta_mfcc13_std']].to_numpy()\n",
    "y_test = test[['label']].to_numpy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "(test.shape[0] + train.shape[0])**0.5"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "183.90214789392755"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classify!\n",
    "\n",
    "Train the classifier with the X_train and Y_train, and then make predictions based on X_test\\\n",
    "Compare the predictions with Y_test and calculate accuracy score and show the confusion matrix"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Train Test Split"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "k = 500#13\n",
    "KNN_model = KNeighborsClassifier(n_neighbors=k)\n",
    "KNN_model.fit(X_train, y_train)\n",
    "KNN_prediction = KNN_model.predict(X_test)\n",
    "print(accuracy_score(KNN_prediction, y_test))\n",
    "\n",
    "print(classification_report(KNN_prediction, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6536454660837682\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean       0.00      0.00      0.00        64\n",
      "     highfry       0.00      0.29      0.01         7\n",
      "     layered       0.00      0.00      0.00         0\n",
      "      lowfry       0.00      0.00      0.00         0\n",
      "      midfry       0.71      0.49      0.58      5676\n",
      "   no_vocals       0.79      0.77      0.78      8435\n",
      "\n",
      "    accuracy                           0.65     14182\n",
      "   macro avg       0.25      0.26      0.23     14182\n",
      "weighted avg       0.75      0.65      0.69     14182\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "cm = confusion_matrix(y_test, KNN_prediction) #'midfry' :0, 'clean' :1, 'highfry' :2,'lowfry' :3, 'layered' :4}\n",
    "print(cm)\n",
    "score=precision_score(y_test, KNN_prediction, average='macro')\n",
    "print(score)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[   0    0    0    0  150  324]\n",
      " [   0    2    0    0  393  269]\n",
      " [   0    0    0    0  342  143]\n",
      " [   0    0    0    0  281  113]\n",
      " [  60    4    0    0 2775 1093]\n",
      " [   4    1    0    0 1735 6493]]\n",
      "0.25739729005916406\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "k_plt=[]\n",
    "score_plt=[]\n",
    "for k in range(100,1000):\n",
    "    \n",
    "    k_plt.append(k)\n",
    "    KNN_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    KNN_model.fit(X_train, y_train)\n",
    "    KNN_prediction = KNN_model.predict(X_test)\n",
    "    score=precision_score(y_test, KNN_prediction, average='macro')\n",
    "    score_plt.append(score)\n",
    "\n",
    "plt.plot(k_plt,score_plt)\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from matplotlib import pyplot as plt \n",
    "k_plt=[]\n",
    "score_plt=[]\n",
    "k=10\n",
    "if k <=1000:\n",
    "    k_plt.append(k)\n",
    "    KNN_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    KNN_model.fit(X_train, y_train)\n",
    "    KNN_prediction = KNN_model.predict(X_test)\n",
    "    score=precision_score(y_test, KNN_prediction, average='macro')\n",
    "    score_plt.append(score)\n",
    "    k=k*1.05\n",
    "plt.plot(k_plt,score_plt)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}