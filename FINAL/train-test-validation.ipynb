{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sys import platform\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    # linux\n",
    "    path='/home/vedant/projects/'\n",
    "elif platform == \"darwin\":\n",
    "    # OS X\n",
    "    path='/Users/vedant/Desktop/Programming/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['video_id', 'start_time', 'mid_ts', 'label', 'average_zcr',\n",
    "       'zcr_stddev', 'mfcc1_mean', 'mfcc2_mean', 'mfcc3_mean',\n",
    "       'mfcc4_mean', 'mfcc5_mean', 'mfcc6_mean', 'mfcc7_mean', 'mfcc8_mean',\n",
    "       'mfcc9_mean', 'mfcc10_mean', 'mfcc11_mean', 'mfcc12_mean',\n",
    "       'mfcc13_mean', 'mfcc1_std', 'mfcc2_std', 'mfcc3_std', 'mfcc4_std',\n",
    "       'mfcc5_std', 'mfcc6_std', 'mfcc7_std', 'mfcc8_std', 'mfcc9_std',\n",
    "       'mfcc10_std', 'mfcc11_std', 'mfcc12_std', 'mfcc13_std',\n",
    "       'delta_mfcc1_mean', 'delta_mfcc2_mean', 'delta_mfcc3_mean',\n",
    "       'delta_mfcc4_mean', 'delta_mfcc5_mean', 'delta_mfcc6_mean',\n",
    "       'delta_mfcc7_mean', 'delta_mfcc8_mean', 'delta_mfcc9_mean',\n",
    "       'delta_mfcc10_mean', 'delta_mfcc11_mean', 'delta_mfcc12_mean',\n",
    "       'delta_mfcc13_mean', 'delta_mfcc1_std', 'delta_mfcc2_std',\n",
    "       'delta_mfcc3_std', 'delta_mfcc4_std', 'delta_mfcc5_std',\n",
    "       'delta_mfcc6_std', 'delta_mfcc7_std', 'delta_mfcc8_std',\n",
    "       'delta_mfcc9_std', 'delta_mfcc10_std', 'delta_mfcc11_std',\n",
    "       'delta_mfcc12_std', 'delta_mfcc13_std',\n",
    "       'centroid_mean','centroid_std',\n",
    "       'contrast_mean','contrast_std',\n",
    "       'flatness_mean','flatness_std',\n",
    "       'rolloff_mean','rolloff_std','rms_mean','rms_std','vggish']\n",
    "       \n",
    "d=np.load(path+'ScreamDetection/resources/working_data/vocal_only_features.npy',allow_pickle=True)\n",
    "df = pd.DataFrame(d,columns=cols)\n",
    "\n",
    "lut = pd.read_csv(path+'/ScreamDetection/resources/working_data/dataset/lookup_new.csv')\n",
    "\n",
    "df.drop('vggish',axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df=df\n",
    "mapping=[]\n",
    "for index,row in feature_df.iterrows():\n",
    "    if row['label'] == 'clean':\n",
    "        mapping.append(0)\n",
    "    if row['label'] == 'highfry':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'layered':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'lowfry':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'midfry':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'no_vocals':\n",
    "        mapping.append(2)\n",
    "\n",
    "feature_df.insert(4,'label_mapped',mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['video_id', 'start_time', 'mid_ts', 'label', 'label_mapped',\n",
    "       'average_zcr', 'zcr_stddev', 'mfcc1_mean', 'mfcc2_mean', 'mfcc3_mean',\n",
    "       'mfcc4_mean', 'mfcc5_mean', 'mfcc6_mean', 'mfcc7_mean', 'mfcc8_mean',\n",
    "       'mfcc9_mean', 'mfcc10_mean', 'mfcc11_mean', 'mfcc12_mean',\n",
    "       'mfcc13_mean', 'mfcc1_std', 'mfcc2_std', 'mfcc3_std', 'mfcc4_std',\n",
    "       'mfcc5_std', 'mfcc6_std', 'mfcc7_std', 'mfcc8_std', 'mfcc9_std',\n",
    "       'mfcc10_std', 'mfcc11_std', 'mfcc12_std', 'mfcc13_std',\n",
    "       'delta_mfcc1_mean', 'delta_mfcc2_mean', 'delta_mfcc3_mean',\n",
    "       'delta_mfcc4_mean', 'delta_mfcc5_mean', 'delta_mfcc6_mean',\n",
    "       'delta_mfcc7_mean', 'delta_mfcc8_mean', 'delta_mfcc9_mean',\n",
    "       'delta_mfcc10_mean', 'delta_mfcc11_mean', 'delta_mfcc12_mean',\n",
    "       'delta_mfcc13_mean', 'delta_mfcc1_std', 'delta_mfcc2_std',\n",
    "       'delta_mfcc3_std', 'delta_mfcc4_std', 'delta_mfcc5_std',\n",
    "       'delta_mfcc6_std', 'delta_mfcc7_std', 'delta_mfcc8_std',\n",
    "       'delta_mfcc9_std', 'delta_mfcc10_std', 'delta_mfcc11_std',\n",
    "       'delta_mfcc12_std', 'delta_mfcc13_std', 'centroid_mean', 'centroid_std',\n",
    "       'contrast_mean', 'contrast_std', 'flatness_mean', 'flatness_std',\n",
    "       'rolloff_mean', 'rolloff_std', 'rms_mean', 'rms_std']\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "undersample = RandomUnderSampler(sampling_strategy='not minority',random_state=0)\n",
    "from collections import Counter\n",
    "X = feature_df.to_numpy()\n",
    "y=feature_df[['label_mapped']].to_numpy()\n",
    "\n",
    "X_under, y_under = undersample.fit_resample(X, y)\n",
    "\n",
    "undersampled_data = pd.DataFrame(X_under,columns=cols)\n",
    "undersampled_data['label_mapped'] = y_under\n",
    "#print(undersampled_data)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "train_inds, test_inds = next(GroupShuffleSplit(test_size=.2, n_splits=2, random_state = 42).split(lut, groups=lut['band_name']))\n",
    "\n",
    "train = lut.iloc[train_inds]\n",
    "test = lut.iloc[test_inds]\n",
    "\n",
    "train_ids = train['video_id'].to_numpy()\n",
    "test_ids = test['video_id'].to_numpy()\n",
    "\n",
    "#df_final = df\n",
    "df_final = undersampled_data\n",
    "train = df_final[df_final.video_id.isin(train_ids)]\n",
    "test = df_final[df_final.video_id.isin(test_ids)]\n",
    "\n",
    "\n",
    "features=['average_zcr', 'zcr_stddev', 'mfcc1_mean', 'mfcc2_mean', 'mfcc3_mean',\n",
    "       'mfcc4_mean', 'mfcc5_mean', 'mfcc6_mean', 'mfcc7_mean', 'mfcc8_mean',\n",
    "       'mfcc9_mean', 'mfcc10_mean', 'mfcc11_mean', 'mfcc12_mean',\n",
    "       'mfcc13_mean', 'mfcc1_std', 'mfcc2_std', 'mfcc3_std', 'mfcc4_std',\n",
    "       'mfcc5_std', 'mfcc6_std', 'mfcc7_std', 'mfcc8_std', 'mfcc9_std',\n",
    "       'mfcc10_std', 'mfcc11_std', 'mfcc12_std', 'mfcc13_std',\n",
    "       'delta_mfcc1_mean', 'delta_mfcc2_mean', 'delta_mfcc3_mean',\n",
    "       'delta_mfcc4_mean', 'delta_mfcc5_mean', 'delta_mfcc6_mean',\n",
    "       'delta_mfcc7_mean', 'delta_mfcc8_mean', 'delta_mfcc9_mean',\n",
    "       'delta_mfcc10_mean', 'delta_mfcc11_mean', 'delta_mfcc12_mean',\n",
    "       'delta_mfcc13_mean', 'delta_mfcc1_std', 'delta_mfcc2_std',\n",
    "       'delta_mfcc3_std', 'delta_mfcc4_std', 'delta_mfcc5_std',\n",
    "       'delta_mfcc6_std', 'delta_mfcc7_std', 'delta_mfcc8_std',\n",
    "       'delta_mfcc9_std', 'delta_mfcc10_std', 'delta_mfcc11_std',\n",
    "       'delta_mfcc12_std', 'delta_mfcc13_std', 'centroid_mean', 'centroid_std',\n",
    "       'contrast_mean', 'contrast_std', 'flatness_mean', 'flatness_std',\n",
    "       'rolloff_mean', 'rolloff_std', 'rms_mean', 'rms_std']\n",
    "X_train = train[features].to_numpy()\n",
    "y_train_hot = to_categorical(train['label_mapped'].to_numpy())\n",
    "# y_train = train['label_mapped'].to_numpy()\n",
    "\n",
    "X_test1 = test[features].to_numpy()\n",
    "y_test_hot1 = to_categorical(test['label_mapped'].to_numpy())\n",
    "# y_test1= test['label_mapped'].to_numpy()\n",
    "\n",
    "X_test,X_valid,y_test_hot,y_valid_hot=train_test_split(X_test1,y_test_hot1,test_size=0.2, random_state=42)\n",
    "\n",
    "# X_train=np.array(X_train)\n",
    "# X_test=np.array(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "\n",
    "X_train = X_train.reshape(-1, 64)\n",
    "X_test = X_test.reshape(-1, 64)\n",
    "X_valid = X_valid.reshape(-1, 64)\n",
    "\n",
    "np.save(f'{path}ScreamDetection/resources/working_data/x_train.npy', X_train)\n",
    "np.save(f'{path}ScreamDetection/resources/working_data/y_train_hot.npy', y_train_hot)\n",
    "\n",
    "np.save(f'{path}ScreamDetection/resources/working_data/x_test.npy', X_test)\n",
    "np.save(f'{path}ScreamDetection/resources/working_data/y_test_hot.npy', y_test_hot)\n",
    "\n",
    "np.save(f'{path}ScreamDetection/resources/working_data/x_valid.npy', X_valid)\n",
    "np.save(f'{path}ScreamDetection/resources/working_data/y_valid_hot.npy', y_valid_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.load(f'{path}ScreamDetection/resources/working_data/x_train.npy',allow_pickle = True)\n",
    "y_test_hot=np.load(f'{path}ScreamDetection/resources/working_data/y_train_hot.npy',allow_pickle = True)\n",
    "\n",
    "X_test=np.load(f'{path}ScreamDetection/resources/working_data/x_test.npy',allow_pickle = True)\n",
    "y_test_hot=np.load(f'{path}ScreamDetection/resources/working_data/y_test_hot.npy',allow_pickle = True)\n",
    "\n",
    "X_valid=np.load(f'{path}ScreamDetection/resources/working_data/x_valid.npy',allow_pickle = True)\n",
    "y_valid_hot=np.load(f'{path}ScreamDetection/resources/working_data/y_valid_hot.npy',allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
